Работу выполнил Студент группы: М8О-407Б-21 Громов Тимофей Сергеевич

# **Выбор датасета**

В данной работе используется датасет Wine Quality Dataset (Red Wine), содержащий химические характеристики красного вина и его оценку качества.
Датасет представлен в данном репозитории файлом: winequality-red.csv.

Классификация: предсказание переменной quality, преобразованной в бинарный формат:
0 (плохое вино) — если quality ≤ 5
1 (хорошее вино) — если quality ≥ 6

Регрессия: предсказание уровня алкоголя (alcohol), который является непрерывным числовым признаком.

Эта задача имеет практическое применение в винодельческой промышленности.
Анализ качества вина на основе его химических характеристик позволяет винодельческим компаниям
оптимизировать производство, стандартизировать продукцию и разрабатывать новые сорта.

# **Выбор метрик**

Для классификации выбраны следующие метрики:
- Accuracy – доля правильно классифицированных объектов среди всех.
- F1-score – гармоническое среднее между точностью (precision) и полнотой (recall), полезное при несбалансированных данных.

Для регрессии выбраны метрики:
- Mean Squared Error (MSE) – среднеквадратичная ошибка, измеряющая среднюю разницу между предсказанными и истинными значениями.
- R² Score – коэффициент детерминации, показывающий, насколько хорошо модель объясняет вариацию зависимой переменной.

# **Результаты**

| Алгоритм             | Задача           | Бейзлайн | Улучшенный бейзлайн | Самостоятельная реализация алгоритма |
|-----------------------|------------------|----------|----------------------|---------------------------------------|
| KNN                  | классификация    | Accuracy: 0.7063, <br> F1-Score: 0.7473 | Accuracy: 0.7531, <br> F1-Score: 0.7859 | Accuracy: 0.7531, <br> F1-Score: 0.7859 |
|                       | регрессия        | MSE: 0.1009 | MSE: 0.0975 | MSE: 0.097535 |
| Линейные модели       | классификация    | Accuracy: 0.7406; <br> F1-Score: 0.7608 | Accuracy: 0.7406; <br> F1-Score: 0.7608 | Accuracy: 0.78; <br> F1-Score: 0.77 |
|                       | регрессия        | MSE: 0.345823 | MSE: 0.345823 | MSE: 0.345823 |
| Решающее дерево       | классификация    | Accuracy: 0.7312; <br> F1-Score: 0.7571 | Accuracy: 0.7156; <br> F1-Score: 0.7362 | Accuracy: 0.7250; <br> F1-Score: 0.7381 |
|                       | регрессия        | MSE: 0.523473 | MSE: 0.478087 | MSE: 0.453143 |
| Случайный лес         | классификация    | Accuracy: 0.7875; <br> F1-Score: 0.8101 | Accuracy: 0.7906; <br> F1-Score: 0.8134 | Accuracy: 0.7219; <br> F1-Score: 0.7390 |
|                       | регрессия        | MSE: 0.263621 | MSE: 0.258929 | MSE: 0.407392 |
| Градиентный бустинг   | классификация    | Accuracy: 0.7625; <br> F1-Score: 0.7803 | Accuracy: 0.7937; <br> F1-Score: 0.8156 | Accuracy: 0.7219; <br> F1-Score: 0.7390 |
|                       | регрессия        | MSE: 0.267526 | MSE: 0.214853 | MSE: 0.253297 |

Вывод: Улучшенный бейзлайн в большинстве случаев показывает лучшие результаты по сравнению с базовыми моделями, что подтверждает эффективность подбора гиперпараметров. Наибольший прирост качества наблюдается у градиентного бустинга, который демонстрирует наивысшие показатели точности среди всех моделей классификации и регрессии. Самостоятельная реализация алгоритмов в ряде случаев уступает библиотечным решениям, что может быть связано с оптимизацией встроенных методов и сложностью реализации с нуля. Однако для KNN разницы между улучшенным бейзлайном и самостоятельной реализацией не наблюдается, что говорит о корректности реализации метода.
